<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes on Gary Flynn</title><link>https://garyflynn.github.io/tags/kubernetes/</link><description>Recent content in Kubernetes on Gary Flynn</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Thu, 03 Dec 2020 14:57:40 +0000</lastBuildDate><atom:link href="https://garyflynn.github.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>vRealize Automation 8.x – Change Internal Kubernetes IP Range</title><link>https://garyflynn.github.io/post/vrealize-automation-8x-change-internal-kubernetes-ip-range-comments/</link><pubDate>Thu, 03 Dec 2020 14:57:40 +0000</pubDate><guid>https://garyflynn.github.io/post/vrealize-automation-8x-change-internal-kubernetes-ip-range-comments/</guid><description>
Josh - May 3, 2021
We had attempted this in our environment unsuccessfully. After opening a case with vmware, we were informed that these steps are incorrect, and were provided the following procedure: • execute 'vracli upgrade exec -y --prepare --profile k8s-subnets' • take VM snapshot • change the subnets on the same node the upgrade command was started: 'vracli network k8s-subnets --cluster-cidr 10.224.0.0/22 --service-cidr 10.224.4.0/22' • execute upgrade with profile: 'vracli upgrade exec'</description></item><item><title>vRealize Automation 8.x – Change Internal Kubernetes IP Range</title><link>https://garyflynn.github.io/post/vrealize-automation-8x-change-internal-kubernetes-ip-range/</link><pubDate>Thu, 03 Dec 2020 14:57:40 +0000</pubDate><guid>https://garyflynn.github.io/post/vrealize-automation-8x-change-internal-kubernetes-ip-range/</guid><description>
vRealize Automation (vRA) 8.2 added support for changing the IP address range used by the internal Kubernetes cluster, which is great news as many organisation already use the 10.244.0.0/21 address space. Unfortunately if your network already uses the ranges 10.244.0.0/22 or 10.244.4.0/22, you will likely encounter issues, such a provisioning timeouts.
To resolve this issue in vRA 8.2, run the below commands to view your current configuration, and to update to a new range.</description></item><item><title>vRealize Automation 8.x - vRA Not Starting if K8s IP Range is Changed</title><link>https://garyflynn.github.io/post/vrealize-automation-8x-vra-not-starting-if-k8s-ip-range-is-changed-comments/</link><pubDate>Wed, 25 Nov 2020 17:59:06 +0000</pubDate><guid>https://garyflynn.github.io/post/vrealize-automation-8x-vra-not-starting-if-k8s-ip-range-is-changed-comments/</guid><description>
vRealize Automation 8.x – Change Internal Kubernetes IP Range – Gary Flynn - Dec 4, 2020
[…] when the Kubernetes internal IP address space is changed to use the 192.168.0.0/16 address space. This post resolves the issue, while VMware develop a patch to resolve the […]</description></item><item><title>vRealize Automation 8.x - vRA Not Starting if K8s IP Range is Changed</title><link>https://garyflynn.github.io/post/vrealize-automation-8x-vra-not-starting-if-k8s-ip-range-is-changed/</link><pubDate>Wed, 25 Nov 2020 17:59:06 +0000</pubDate><guid>https://garyflynn.github.io/post/vrealize-automation-8x-vra-not-starting-if-k8s-ip-range-is-changed/</guid><description>
vRealize Automation (vRA) 8.0 introduced a completely new architecture by running the vRA application itself on top of a Kubernetes (k8s) cluster. Unfortunately this was released with a hardcoded IP address range used by the internal k8s cluster. If your corporate network happened to be using the same IP addresses that were selected by the k8s cluster, then you would likely see plenty of errors in vRA.
Thankfully, vRealize Automation 8.</description></item></channel></rss>